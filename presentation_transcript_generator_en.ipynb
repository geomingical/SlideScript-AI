{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8af82ae5",
   "metadata": {},
   "source": [
    "# üé§ Presentation Transcript Generator\n",
    "\n",
    "> **Professional AI-Powered Slide-to-Speech Tool** - Transform presentation slides into natural, fluent speech transcripts using AI Agent technology\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ú® Features\n",
    "\n",
    "- üìä **Smart Slide Analysis** - Automatically parse PDF presentation content\n",
    "- üéôÔ∏è **Speech Rate Detection** - Upload 20-second audio to automatically calculate speaking speed\n",
    "- üé≠ **Multiple Speech Styles** - Supports lively, serious, motivational, educational, and conversational styles\n",
    "- üåê **Multilingual Support** - Traditional Chinese, English, Simplified Chinese, Japanese, Korean, Spanish, French, and German\n",
    "- üë®‚Äçüè´ **Expert Role Playing** - AI generates content from domain expert perspectives\n",
    "- üì• **One-Click Download** - Export in multiple formats\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Workflow\n",
    "\n",
    "1. **Environment Setup** - Install necessary packages\n",
    "2. **Configure Parameters** - Set speech duration, style, language, etc.\n",
    "3. **Upload Files** - Upload presentation PDF and audio (optional)\n",
    "4. **Generate Transcript** - AI automatically generates professional transcript\n",
    "5. **Download Results** - Get complete transcript file\n",
    "\n",
    "---\n",
    "\n",
    "**Last Updated**: December 2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d021ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# ÂÆâË£ùÂøÖË¶ÅÂ•ó‰ª∂\n",
    "!pip install -q pymupdf pillow\n",
    "!pip install -q pydub\n",
    "!pip install -q openai\n",
    "!pip install -q ipywidgets\n",
    "!apt-get install -qq ffmpeg\n",
    "\n",
    "print(\"‚úÖ All packages installed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07660a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "\n",
    "# Import third-party libraries\n",
    "import fitz  # PyMuPDF\n",
    "from PIL import Image\n",
    "from pydub import AudioSegment\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Configure warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Modules imported successfully!\")\n",
    "print(\"üìå Please set your API Key in the next step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a77eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure CSS styles - Use Noto Sans TC font\n",
    "custom_css = \"\"\"\n",
    "<style>\n",
    "@import url('https://fonts.googleapis.com/css2?family=Noto+Sans+TC:wght@300;400;500;700&display=swap');\n",
    "\n",
    "* {\n",
    "    font-family: 'Noto Sans TC', 'Segoe UI', Arial, sans-serif !important;\n",
    "}\n",
    "\n",
    ".widget-label {\n",
    "    font-weight: 500 !important;\n",
    "    color: #2c3e50 !important;\n",
    "    font-size: 14px !important;\n",
    "}\n",
    "\n",
    ".widget-text input, .widget-textarea textarea, .widget-dropdown select {\n",
    "    border: 2px solid #e0e0e0 !important;\n",
    "    border-radius: 8px !important;\n",
    "    padding: 10px !important;\n",
    "    font-size: 14px !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "}\n",
    "\n",
    ".widget-text input:focus, .widget-textarea textarea:focus, .widget-dropdown select:focus {\n",
    "    border-color: #4CAF50 !important;\n",
    "    box-shadow: 0 0 0 3px rgba(76, 175, 80, 0.1) !important;\n",
    "    outline: none !important;\n",
    "}\n",
    "\n",
    ".widget-button {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;\n",
    "    color: white !important;\n",
    "    border: none !important;\n",
    "    border-radius: 8px !important;\n",
    "    padding: 12px 24px !important;\n",
    "    font-weight: 500 !important;\n",
    "    font-size: 14px !important;\n",
    "    cursor: pointer !important;\n",
    "    transition: all 0.3s ease !important;\n",
    "}\n",
    "\n",
    ".widget-button:hover {\n",
    "    transform: translateY(-2px) !important;\n",
    "    box-shadow: 0 5px 15px rgba(102, 126, 234, 0.4) !important;\n",
    "}\n",
    "\n",
    ".success-box {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    color: white;\n",
    "    padding: 20px;\n",
    "    border-radius: 12px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0 4px 15px rgba(0,0,0,0.1);\n",
    "}\n",
    "\n",
    ".info-box {\n",
    "    background: #f8f9fa;\n",
    "    border-left: 4px solid #667eea;\n",
    "    padding: 15px;\n",
    "    border-radius: 8px;\n",
    "    margin: 15px 0;\n",
    "}\n",
    "\n",
    ".transcript-output {\n",
    "    background: white;\n",
    "    border: 2px solid #e0e0e0;\n",
    "    border-radius: 12px;\n",
    "    padding: 25px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0 2px 10px rgba(0,0,0,0.05);\n",
    "    max-height: 500px;\n",
    "    overflow-y: auto;\n",
    "}\n",
    "\n",
    ".slide-header {\n",
    "    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n",
    "    color: white;\n",
    "    padding: 12px 20px;\n",
    "    border-radius: 8px;\n",
    "    font-weight: 600;\n",
    "    font-size: 16px;\n",
    "    margin-top: 20px;\n",
    "    margin-bottom: 10px;\n",
    "}\n",
    "\n",
    ".slide-content {\n",
    "    color: #2c3e50;\n",
    "    line-height: 1.8;\n",
    "    font-size: 15px;\n",
    "    padding: 10px 20px;\n",
    "}\n",
    "\n",
    ".progress-indicator {\n",
    "    background: #f8f9fa;\n",
    "    border-radius: 12px;\n",
    "    padding: 20px;\n",
    "    margin: 15px 0;\n",
    "    border: 2px solid #e0e0e0;\n",
    "}\n",
    "\n",
    "h1, h2, h3 {\n",
    "    color: #2c3e50 !important;\n",
    "    font-weight: 600 !important;\n",
    "}\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(custom_css))\n",
    "print(\"‚úÖ UI style configuration complete! Using Noto Sans TC font\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ff1110",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFProcessor:\n",
    "    \"\"\"Class for processing PDF slides\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.slides_content = []\n",
    "    \n",
    "    def extract_slides(self, pdf_path: str) -> List[Dict[str, str]]:\n",
    "        \"\"\"\n",
    "        Extract content from each page of the PDF\n",
    "        \n",
    "        Args:\n",
    "            pdf_path: Path to the PDF file\n",
    "            \n",
    "        Returns:\n",
    "            List of page content [{\"page\": 1, \"text\": \"...\", \"image\": \"...\"}, ...]\n",
    "        \"\"\"\n",
    "        try:\n",
    "            doc = fitz.open(pdf_path)\n",
    "            \n",
    "            # Check if PDF is empty\n",
    "            if len(doc) == 0:\n",
    "                doc.close()\n",
    "                raise Exception(\"This PDF file does not contain any pages\")\n",
    "            \n",
    "            slides = []\n",
    "            \n",
    "            for page_num in range(len(doc)):\n",
    "                page = doc[page_num]\n",
    "                \n",
    "                # Extract text\n",
    "                text = page.get_text().strip()\n",
    "                \n",
    "                # Convert to image (for visualization or OCR)\n",
    "                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))\n",
    "                img_data = pix.tobytes(\"png\")\n",
    "                \n",
    "                slides.append({\n",
    "                    \"page\": page_num + 1,\n",
    "                    \"text\": text if text else \"[No text content on this page]\",\n",
    "                    \"image\": base64.b64encode(img_data).decode()\n",
    "                })\n",
    "            \n",
    "            doc.close()\n",
    "            self.slides_content = slides\n",
    "            return slides\n",
    "            \n",
    "        except Exception as e:\n",
    "            if \"PDF\" in str(e):\n",
    "                raise Exception(f\"PDF processing error: {str(e)}\")\n",
    "            else:\n",
    "                raise Exception(f\"PDF processing error: Unable to read file, please check if the file format is correct\")\n",
    "    \n",
    "    def get_slide_summary(self) -> str:\n",
    "        \"\"\"Get slide summary\"\"\"\n",
    "        if not self.slides_content:\n",
    "            return \"No slides loaded yet\"\n",
    "        \n",
    "        summary = f\"Total {len(self.slides_content)} slides\\n\\n\"\n",
    "        for slide in self.slides_content[:3]:  # Show preview of first 3 slides\n",
    "            summary += f\"üìÑ Page {slide['page']}:\\n{slide['text'][:100]}...\\n\\n\"\n",
    "        \n",
    "        if len(self.slides_content) > 3:\n",
    "            summary += f\"...and {len(self.slides_content) - 3} other pages\"\n",
    "        \n",
    "        return summary\n",
    "\n",
    "\n",
    "class AudioAnalyzer:\n",
    "    \"\"\"Analyze audio and calculate speech rate using GPT-4o Audio API\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.words_per_minute = None\n",
    "    \n",
    "    def _convert_m4a_to_mp3(self, audio_path: str) -> str:\n",
    "        \"\"\"Convert m4a format to mp3\"\"\"\n",
    "        try:\n",
    "            audio = AudioSegment.from_file(audio_path)\n",
    "            mp3_path = \"/tmp/converted_audio.mp3\"\n",
    "            audio.export(mp3_path, format=\"mp3\", bitrate=\"128k\")\n",
    "            return mp3_path\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Audio format conversion error: {str(e)}\")\n",
    "    \n",
    "    def analyze_audio(self, audio_path: str) -> float:\n",
    "        \"\"\"Analyze audio and calculate speech rate using GPT-4o Audio API\"\"\"\n",
    "        try:\n",
    "            audio = AudioSegment.from_file(audio_path)\n",
    "            duration_seconds = len(audio) / 1000.0\n",
    "            \n",
    "            # Check audio duration\n",
    "            if duration_seconds < 5:\n",
    "                raise Exception(\"Audio duration too short (less than 5 seconds), suggest uploading around 20 seconds for more accurate results\")\n",
    "            if duration_seconds > 120:\n",
    "                raise Exception(\"Audio duration too long (over 2 minutes), please upload a 20-60 second audio sample\")\n",
    "            \n",
    "            # Convert m4a to mp3 if necessary\n",
    "            if audio_path.lower().endswith('.m4a'):\n",
    "                print(\"üîÑ m4a format detected, converting to mp3...\")\n",
    "                audio_path = self._convert_m4a_to_mp3(audio_path)\n",
    "            \n",
    "            # Transcribe using GPT-4o Audio API\n",
    "            print(\"üéôÔ∏è Analyzing with GPT-4o Audio API...\")\n",
    "            \n",
    "            with open(audio_path, 'rb') as audio_file:\n",
    "                transcription = self.client.audio.transcriptions.create(\n",
    "                    model=\"whisper-1\",\n",
    "                    file=audio_file,\n",
    "                    language=\"zh\"\n",
    "                )\n",
    "            \n",
    "            text = transcription.text\n",
    "            \n",
    "            # Check for transcription content\n",
    "            if not text or len(text.strip()) == 0:\n",
    "                raise Exception(\"Unable to recognize audio content, please ensure audio is clear and contains speech\")\n",
    "            \n",
    "            # Calculate character count (Chinese characters counted individually)\n",
    "            char_count = len([c for c in text if c.strip() and not c.isspace()])\n",
    "            \n",
    "            # Calculate words per minute\n",
    "            wpm = (char_count / duration_seconds) * 60\n",
    "            self.words_per_minute = wpm\n",
    "            \n",
    "            # Clean up temporary files\n",
    "            if audio_path.startswith(\"/tmp/\"):\n",
    "                if os.path.exists(audio_path):\n",
    "                    os.remove(audio_path)\n",
    "            \n",
    "            return wpm\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Clean up temporary files (even if error occurs)\n",
    "            if 'audio_path' in locals() and audio_path.startswith(\"/tmp/\"):\n",
    "                if os.path.exists(audio_path):\n",
    "                    os.remove(audio_path)\n",
    "            raise Exception(f\"Audio analysis error: {str(e)}\")\n",
    "\n",
    "\n",
    "class TranscriptGenerator:\n",
    "    \"\"\"Generate speech transcript using OpenAI Vision models (Supports GPT-5.1/o3/GPT-4o/GPT-4o-mini)\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key: str):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.transcript = \"\"\n",
    "        self.use_vision = True\n",
    "    \n",
    "    def generate_transcript(\n",
    "        self,\n",
    "        slides: List[Dict[str, str]],\n",
    "        target_duration: int,\n",
    "        words_per_minute: float,\n",
    "        style: str,\n",
    "        topic: str,\n",
    "        audience: str,\n",
    "        language: str,\n",
    "        model_name: str = \"gpt-5.1\",\n",
    "        expert_role: Optional[str] = None,\n",
    "        include_tips: bool = False\n",
    "    ) -> str:\n",
    "        \"\"\"Generate speech transcript (supports multi-language, multi-model, and speech tips)\"\"\"\n",
    "        try:\n",
    "            # Check if slides are empty\n",
    "            if not slides or len(slides) == 0:\n",
    "                raise Exception(\"No slide content, please upload a PDF file first\")\n",
    "            \n",
    "            # Calculate target word count\n",
    "            target_words = int(target_duration * words_per_minute)\n",
    "            words_per_slide = target_words // len(slides)\n",
    "            \n",
    "            # Create system prompt\n",
    "            system_prompt = self._create_system_prompt(\n",
    "                style, topic, audience, language, expert_role, words_per_slide, include_tips\n",
    "            )\n",
    "            \n",
    "            # Display generation info\n",
    "            model_names = {\n",
    "                'gpt-5.1': 'GPT-5.1 (Strongest Multimodal Understanding)',\n",
    "                'o3': 'o3 (Strong Reasoning Model)',\n",
    "                'gpt-4o': 'GPT-4o (Balanced All-rounder)',\n",
    "                'gpt-4o-mini': 'GPT-4o-mini (Fast and Economical)'\n",
    "            }\n",
    "            print(f\"ü§ñ Generating transcript using {model_names.get(model_name, model_name)}...\")\n",
    "            print(f\"üìä Target word count: {target_words} words\")\n",
    "            print(f\"üìÑ Number of slides: {len(slides)} pages\")\n",
    "            print(f\"üåê Output language: {language}\")\n",
    "            if include_tips:\n",
    "                print(\"üí° Including speech tips (gestures, tone, pauses, etc.)\")\n",
    "            \n",
    "            # Build prompt content\n",
    "            tips_instruction = \"\"\n",
    "            if include_tips:\n",
    "                tips_instruction = \"\"\"\n",
    "\n",
    "„ÄêSpeech Tips Suggestions„Äë\n",
    "Please include the following speech tips in appropriate places within the transcript (marked with [square brackets]):\n",
    "- [Gesture: Open arms] - When emphasizing a key point\n",
    "- [Gesture: Point to slide] - When explaining a chart\n",
    "- [Tone: Raise volume] - For key messages\n",
    "- [Tone: Slow down] - For important concepts\n",
    "- [Pause 2-3 seconds] - During section transitions\n",
    "- [Eye contact] - When interacting with the audience\n",
    "- [Movement: Move to center stage] - During opening or closing\n",
    "\"\"\"\n",
    "            \n",
    "            user_content = [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"\"\"\n",
    "Please generate a complete speech transcript based on the following slide images.\n",
    "\n",
    "Speech Parameters:\n",
    "- Total Duration: {target_duration} minutes\n",
    "- Speech Rate: Approximately {int(words_per_minute)} words per minute\n",
    "- Target Total Word Count: Approximately {target_words} words\n",
    "- Suggested Words per Slide: Approximately {words_per_slide} words\n",
    "- Output Language: {language}{tips_instruction}\n",
    "\n",
    "Output Format Requirements:\n",
    "Slide 1\n",
    "[Speech content for slide 1]\n",
    "\n",
    "Slide 2\n",
    "[Speech content for slide 2]\n",
    "\n",
    "...and so on\n",
    "\n",
    "Please ensure:\n",
    "1. Carefully observe the visual elements, charts, and text on each slide\n",
    "2. The transcript for each page is natural and smooth, explaining the key points on the slide\n",
    "3. Content flows smoothly with a clear opening and closing\n",
    "4. Matches the specified speech style and tone\n",
    "5. Total word count is around {target_words} words (allow 10% variance)\n",
    "\"\"\"\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            # Add all slide images\n",
    "            for slide in slides:\n",
    "                user_content.append({\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{slide['image']}\",\n",
    "                        \"detail\": \"high\"\n",
    "                    }\n",
    "                })\n",
    "            # Call OpenAI Vision API (Supports GPT-5.1/o3/GPT-4o/GPT-4o-mini)\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_content}\n",
    "                ],\n",
    "                temperature=0.7,\n",
    "                max_completion_tokens=4000\n",
    "            )\n",
    "            \n",
    "            transcript = response.choices[0].message.content\n",
    "            self.transcript = transcript\n",
    "            \n",
    "            return transcript\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = str(e)\n",
    "            if \"API key\" in error_msg or \"authentication\" in error_msg.lower():\n",
    "                raise Exception(\"‚ùå API Key error, please check if your OpenAI API Key is correct\")\n",
    "            elif \"rate limit\" in error_msg.lower():\n",
    "                raise Exception(\"‚ùå API request limit reached, please try again later\")\n",
    "            elif \"quota\" in error_msg.lower():\n",
    "                raise Exception(\"‚ùå API quota exceeded, please check your OpenAI account balance\")\n",
    "            else:\n",
    "                raise Exception(f\"Transcript generation error: {error_msg}\")\n",
    "    \n",
    "    def _create_system_prompt(\n",
    "        self,\n",
    "        style: str,\n",
    "        topic: str,\n",
    "        audience: str,\n",
    "        language: str,\n",
    "        expert_role: Optional[str],\n",
    "        words_per_slide: int,\n",
    "        include_tips: bool = False\n",
    "    ) -> str:\n",
    "        \"\"\"Create system prompt\"\"\"\n",
    "        \n",
    "        style_descriptions = {\n",
    "            \"Lively\": \"Use a relaxed, lively tone with appropriate interactive and humorous elements\",\n",
    "            \"Serious\": \"Use a formal, professional tone maintaining academic rigor\",\n",
    "            \"Motivational\": \"Use inspiring language full of positive energy and motivation\",\n",
    "            \"Educational\": \"Use clear, easy-to-understand explanations, as if teaching students\",\n",
    "            \"Conversational\": \"Use a conversational tone, as if talking face-to-face with the audience\"\n",
    "        }\n",
    "        \n",
    "        language_instructions = {\n",
    "            \"Traditional Chinese\": \"Output in Traditional Chinese\",\n",
    "            \"English\": \"Output in English\",\n",
    "            \"Simplified Chinese\": \"Output in Simplified Chinese\",\n",
    "            \"Japanese\": \"Output in Japanese\",\n",
    "            \"Korean\": \"Output in Korean\",\n",
    "            \"Spanish\": \"Output in Spanish\",\n",
    "            \"French\": \"Output in French\",\n",
    "            \"German\": \"Output in German\"\n",
    "        }\n",
    "        \n",
    "        role_intro = \"\"\n",
    "        if expert_role:\n",
    "            role_intro = f\"You are a {expert_role}, \"\n",
    "        \n",
    "        style_desc = style_descriptions.get(style, \"Use a natural and smooth tone\")\n",
    "        lang_inst = language_instructions.get(language, \"Output in Traditional Chinese\")\n",
    "        \n",
    "        tips_requirement = \"\"\n",
    "        if include_tips:\n",
    "            tips_requirement = \"\"\"\n",
    "7. Include speech tips suggestions in appropriate places, marked with [square brackets], including:\n",
    "   - Gesture suggestions (e.g., open arms, point to slide, clench fist for emphasis)\n",
    "   - Tone suggestions (e.g., raise volume, slow down, emphasize)\n",
    "   - Pause timing (e.g., [Pause 2-3 seconds])\n",
    "   - Body language (e.g., eye contact, movement, lean forward)\n",
    "   These suggestions should blend naturally into the transcript to help the speaker better convey the message\n",
    "\"\"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "{role_intro}You are an experienced speaker and content creation expert.\n",
    "\n",
    "Speech Topic: {topic}\n",
    "Target Audience: {audience}\n",
    "Speech Style: {style_desc}\n",
    "Language Requirement: {lang_inst}\n",
    "\n",
    "Your task is to create a natural, smooth, and engaging speech transcript based on the provided slide content.\n",
    "\n",
    "Requirements:\n",
    "1. Content must be faithful to the slides but expressed in spoken language\n",
    "2. Approximately {words_per_slide} words per page, adjustable based on content importance\n",
    "3. Opening must be attractive, closing must be powerful\n",
    "4. Add transition phrases appropriately to ensure smooth flow\n",
    "5. Match the specified speech style and target audience\n",
    "6. Ensure content is professional and accurate, yet easy to understand{tips_requirement}\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ Core functionality classes created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b617e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "import getpass\n",
    "\n",
    "# Try to load from Colab Secrets\n",
    "try:\n",
    "    OPENAI_API_KEY = userdata.get('GPT_API_KEY')\n",
    "    print(\"‚úÖ API Key loaded from Colab Secrets\")\n",
    "except:\n",
    "    # Manual input\n",
    "    print(\"üîë Please enter your OpenAI API Key:\")\n",
    "    print(\"üí° Hint: You can store the API Key in Colab's 'Secrets' feature\")\n",
    "    OPENAI_API_KEY = getpass.getpass(\"API Key: \")\n",
    "    \n",
    "if OPENAI_API_KEY:\n",
    "    print(\"‚úÖ API Key set successfully!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Warning: API Key not set, AI generation features unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4cd364",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranscriptGeneratorUI:\n",
    "    \"\"\"Interactive User Interface\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.pdf_processor = PDFProcessor()\n",
    "        self.audio_analyzer = None  # Delayed initialization, requires API key\n",
    "        self.transcript_generator = None\n",
    "        \n",
    "        # Store uploaded files\n",
    "        self.pdf_path = None\n",
    "        self.audio_path = None\n",
    "        self.current_wpm = 200  # Current speech rate\n",
    "        \n",
    "        # Create UI widgets\n",
    "        self._create_widgets()\n",
    "    \n",
    "    def _create_widgets(self):\n",
    "        \"\"\"Create all UI widgets\"\"\"\n",
    "        \n",
    "        # Title\n",
    "        display(HTML(\"\"\"\n",
    "        <div class=\"success-box\">\n",
    "            <h2 style=\"color: white; margin: 0;\">üé§ Speech Transcript Generator</h2>\n",
    "            <p style=\"color: white; margin: 10px 0 0 0; opacity: 0.9;\">\n",
    "                Easily convert slides into professional speech transcripts\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "        \n",
    "        # 1. Upload PDF\n",
    "        display(HTML(\"<div class='info-box'><h3>üìÑ Step 1: Upload Slide PDF</h3></div>\"))\n",
    "        self.pdf_upload = widgets.FileUpload(\n",
    "            accept='.pdf',\n",
    "            multiple=False,\n",
    "            description='Select PDF'\n",
    "        )\n",
    "        self.pdf_status = widgets.HTML(value=\"<p style='color: #666;'>Not uploaded</p>\")\n",
    "        display(self.pdf_upload, self.pdf_status)\n",
    "        \n",
    "        # 2. Set Speech Duration\n",
    "        display(HTML(\"<div class='info-box'><h3>‚è±Ô∏è Step 2: Set Speech Duration</h3></div>\"))\n",
    "        self.duration_input = widgets.IntText(\n",
    "            value=10,\n",
    "            description='Duration',\n",
    "            min=1,\n",
    "            max=180,\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        display(widgets.HBox([self.duration_input, widgets.Label('Minutes')]))\n",
    "        \n",
    "        # 3. Speech Rate Settings\n",
    "        display(HTML(\"<div class='info-box'><h3>üéôÔ∏è Step 3: Set Speech Rate</h3></div>\"))\n",
    "        \n",
    "        # Speech rate selection dropdown\n",
    "        self.speed_preset = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('Slow (150 wpm)', 150),\n",
    "                ('Medium (200 wpm)', 200),\n",
    "                ('Fast (250 wpm)', 250),\n",
    "                ('Auto Analysis (Upload 20s audio)', 0)\n",
    "            ],\n",
    "            value=200,\n",
    "            description='Speech Rate',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        display(self.speed_preset)\n",
    "        \n",
    "        # Audio upload area (used when \"Auto Analysis\" is selected)\n",
    "        self.audio_container = widgets.VBox([\n",
    "            widgets.HTML(\"<p style='color: #666; font-size: 13px; margin: 10px 0;'>üí° After selecting 'Auto Analysis', please upload 20 seconds of audio</p>\")\n",
    "        ])\n",
    "        \n",
    "        self.audio_upload = widgets.FileUpload(\n",
    "            accept='.m4a,.mp3,.wav',\n",
    "            multiple=False,\n",
    "            description='Upload Audio',\n",
    "            layout=widgets.Layout(display='none')  # Hidden by default\n",
    "        )\n",
    "        self.audio_status = widgets.HTML(value=\"\")\n",
    "        self.analyze_button = widgets.Button(\n",
    "            description='üéµ Start Analysis',\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(display='none')  # Hidden by default\n",
    "        )\n",
    "        \n",
    "        self.audio_container.children = self.audio_container.children + (self.audio_upload, self.audio_status, self.analyze_button)\n",
    "        display(self.audio_container)\n",
    "        \n",
    "        # Monitor speech rate selection changes\n",
    "        self.speed_preset.observe(self._on_speed_change, names='value')\n",
    "        \n",
    "        # üÜï 4. AI Model Selection\n",
    "        display(HTML(\"\"\"\n",
    "        <div class='info-box'>\n",
    "            <h3>ü§ñ Step 4: Select AI Model</h3>\n",
    "            <p style='color: #666; font-size: 13px; margin: 5px 0;'>\n",
    "                üí° <strong>GPT-5.1</strong> possesses the strongest multimodal understanding capabilities, enabling deep analysis of images and text\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "        self.model_dropdown = widgets.Dropdown(\n",
    "            options=[\n",
    "                ('GPT-5.1 - Strongest Multimodal (Deep understanding of text & images, Recommended) ‚≠ê', 'gpt-5.1'),\n",
    "                ('o3 - Strong Reasoning (Complex logic analysis)', 'o3'),\n",
    "                ('GPT-4o - Balanced All-rounder (Speed & Quality)', 'gpt-4o'),\n",
    "                ('GPT-4o-mini - Fast & Economical (Basic needs)', 'gpt-4o-mini')\n",
    "            ],\n",
    "            value='gpt-5.1',\n",
    "            description='AI Model',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        display(self.model_dropdown)\n",
    "        \n",
    "        # 5. Speech Style\n",
    "        display(HTML(\"<div class='info-box'><h3>üé≠ Step 5: Select Speech Style</h3></div>\"))\n",
    "        self.style_dropdown = widgets.Dropdown(\n",
    "            options=['Lively', 'Serious', 'Motivational', 'Educational', 'Conversational'],\n",
    "            value='Lively',\n",
    "            description='Speech Style',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        display(self.style_dropdown)\n",
    "        \n",
    "        # 6. Speech Information\n",
    "        display(HTML(\"<div class='info-box'><h3>üìù Step 6: Fill in Speech Info</h3></div>\"))\n",
    "        \n",
    "        self.topic_input = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='e.g., Application of AI in Education',\n",
    "            description='Speech Topic',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        self.audience_input = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='e.g., University Students, Teachers, Tech Enthusiasts',\n",
    "            description='Target Audience',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # Language options\n",
    "        self.language_dropdown = widgets.Dropdown(\n",
    "            options=['Traditional Chinese', 'English', 'Simplified Chinese', 'Japanese', 'Korean', 'Spanish', 'French', 'German'],\n",
    "            value='Traditional Chinese',\n",
    "            description='Output Language',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        # üÜï Expert Role - Add detailed description\n",
    "        display(HTML(\"\"\"\n",
    "        <div style='background: #E3F2FD; border-left: 4px solid #2196F3; padding: 12px; border-radius: 6px; margin: 10px 0;'>\n",
    "            <strong style='color: #1976D2;'>üí° What is an Expert Role?</strong>\n",
    "            <p style='color: #555; font-size: 13px; margin: 8px 0 0 0; line-height: 1.6;'>\n",
    "                AI will <strong>act as the expert you specify</strong> to write the transcript, making the content more professional and persuasive.<br>\n",
    "                ‚Ä¢ e.g., \"Senior AI Researcher\" ‚Üí Explain from a technical expert's perspective<br>\n",
    "                ‚Ä¢ e.g., \"PhD in Educational Psychology\" ‚Üí Explain from an educational expert's perspective<br>\n",
    "                ‚Ä¢ e.g., \"Startup Mentor\" ‚Üí Share insights from practical experience<br>\n",
    "                <em>Leave blank to use a generic speaker persona</em>\n",
    "            </p>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "        \n",
    "        self.expert_role = widgets.Text(\n",
    "            value='',\n",
    "            placeholder='e.g., Senior AI Researcher, PhD in Educational Psychology (Optional)',\n",
    "            description='Expert Role',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='500px')\n",
    "        )\n",
    "        \n",
    "        # Speech tips suggestion option\n",
    "        self.include_tips = widgets.Checkbox(\n",
    "            value=True,\n",
    "            description='Include speech tips suggestions (gestures, tone, pauses, etc.)',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        \n",
    "        display(self.topic_input, self.audience_input, self.language_dropdown, self.expert_role, self.include_tips)\n",
    "        \n",
    "        # 7. Generate Button\n",
    "        display(HTML(\"<div style='margin-top: 30px;'></div>\"))\n",
    "        self.generate_button = widgets.Button(\n",
    "            description='üöÄ Generate Transcript',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='200px', height='50px')\n",
    "        )\n",
    "        display(self.generate_button)\n",
    "        \n",
    "        # 8. Output Area\n",
    "        self.output_area = widgets.Output()\n",
    "        display(self.output_area)\n",
    "        \n",
    "        # Bind events\n",
    "        self.pdf_upload.observe(self._on_pdf_upload, names='value')\n",
    "        self.audio_upload.observe(self._on_audio_upload, names='value')\n",
    "        self.analyze_button.on_click(self._analyze_audio)\n",
    "        self.generate_button.on_click(self._generate_transcript)\n",
    "    \n",
    "    def _on_speed_change(self, change):\n",
    "        \"\"\"Handle speech rate selection changes\"\"\"\n",
    "        if change['new'] == 0:  # \"Auto Analysis\" selected\n",
    "            self.audio_upload.layout.display = 'block'\n",
    "            self.analyze_button.layout.display = 'block'\n",
    "            self.audio_status.value = \"<p style='color: #2196F3;'>üì§ Please upload a 20-second audio file</p>\"\n",
    "        else:\n",
    "            self.audio_upload.layout.display = 'none'\n",
    "            self.analyze_button.layout.display = 'none'\n",
    "            self.audio_status.value = \"\"\n",
    "            self.current_wpm = change['new']\n",
    "    \n",
    "    def _on_pdf_upload(self, change):\n",
    "        \"\"\"Handle PDF upload\"\"\"\n",
    "        if change['new']:\n",
    "            try:\n",
    "                uploaded_file = list(change['new'].values())[0]\n",
    "                filename = uploaded_file['metadata']['name']\n",
    "                file_size = len(uploaded_file['content'])\n",
    "                \n",
    "                # Check file size (suggested < 50MB)\n",
    "                if file_size > 50 * 1024 * 1024:\n",
    "                    self.pdf_status.value = \"<div style='color: #f44336;'>‚ùå File too large (over 50MB), please compress and upload again</div>\"\n",
    "                    return\n",
    "                \n",
    "                # Save PDF\n",
    "                self.pdf_path = \"/tmp/presentation.pdf\"\n",
    "                with open(self.pdf_path, 'wb') as f:\n",
    "                    f.write(uploaded_file['content'])\n",
    "                \n",
    "                # Parse PDF\n",
    "                slides = self.pdf_processor.extract_slides(self.pdf_path)\n",
    "                \n",
    "                self.pdf_status.value = f\"\"\"\n",
    "                <div style='color: #4CAF50; font-weight: 500;'>\n",
    "                    ‚úÖ Uploaded: {filename}<br>\n",
    "                    üìä Total {len(slides)} slides\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.pdf_status.value = f\"<div style='color: #f44336;'>‚ùå Error: {str(e)}</div>\"\n",
    "    \n",
    "    def _on_audio_upload(self, change):\n",
    "        \"\"\"Handle audio upload\"\"\"\n",
    "        if change['new']:\n",
    "            try:\n",
    "                uploaded_file = list(change['new'].values())[0]\n",
    "                \n",
    "                # Save audio\n",
    "                filename = uploaded_file['metadata']['name']\n",
    "                ext = os.path.splitext(filename)[1]\n",
    "                self.audio_path = f\"/tmp/audio{ext}\"\n",
    "                \n",
    "                with open(self.audio_path, 'wb') as f:\n",
    "                    f.write(uploaded_file['content'])\n",
    "                \n",
    "                self.audio_status.value = f\"\"\"\n",
    "                <div style='color: #4CAF50; font-weight: 500;'>\n",
    "                    ‚úÖ Uploaded: {filename}<br>\n",
    "                    üëâ Please click the \"Start Analysis\" button\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.audio_status.value = f\"<div style='color: #f44336;'>‚ùå Error: {str(e)}</div>\"\n",
    "    \n",
    "    def _analyze_audio(self, button):\n",
    "        \"\"\"Analyze audio speech rate using GPT-4o Audio API\"\"\"\n",
    "        if not self.audio_path:\n",
    "            self.audio_status.value = \"<div style='color: #f44336;'>‚ùå Please upload an audio file first</div>\"\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            self.audio_status.value = \"<div style='color: #2196F3;'>‚è≥ Analyzing using GPT-4o Audio API...</div>\"\n",
    "            \n",
    "            # Initialize AudioAnalyzer (requires API key)\n",
    "            if self.audio_analyzer is None:\n",
    "                self.audio_analyzer = AudioAnalyzer(OPENAI_API_KEY)\n",
    "            \n",
    "            wpm = self.audio_analyzer.analyze_audio(self.audio_path)\n",
    "            \n",
    "            # Update current speech rate\n",
    "            self.current_wpm = int(wpm)\n",
    "            \n",
    "            self.audio_status.value = f\"\"\"\n",
    "            <div style='color: #4CAF50; font-weight: 500;'>\n",
    "                ‚úÖ Analysis Complete!<br>\n",
    "                üé§ Your speech rate: {self.current_wpm} words/min\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.audio_status.value = f\"<div style='color: #f44336;'>‚ùå {str(e)}</div>\"\n",
    "    \n",
    "    def _generate_transcript(self, button):\n",
    "        \"\"\"Generate transcript\"\"\"\n",
    "        with self.output_area:\n",
    "            clear_output()\n",
    "            \n",
    "            # Validate input\n",
    "            if not self.pdf_path:\n",
    "                display(HTML(\"<div style='color: #f44336;'>‚ùå Please upload PDF slides first</div>\"))\n",
    "                return\n",
    "            \n",
    "            if not self.topic_input.value:\n",
    "                display(HTML(\"<div style='color: #f44336;'>‚ùå Please fill in the speech topic</div>\"))\n",
    "                return\n",
    "            \n",
    "            if not self.audience_input.value:\n",
    "                display(HTML(\"<div style='color: #f44336;'>‚ùå Please fill in the target audience</div>\"))\n",
    "                return\n",
    "            \n",
    "            try:\n",
    "                display(HTML(\"\"\"\n",
    "                <div class='progress-indicator'>\n",
    "                    <h3>üîÑ Generating transcript...</h3>\n",
    "                    <p>Please wait, this may take some time.</p>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "                \n",
    "                # Initialize generator\n",
    "                self.transcript_generator = TranscriptGenerator(OPENAI_API_KEY)\n",
    "                \n",
    "                # Determine speech rate to use\n",
    "                if self.speed_preset.value == 0:  # Auto Analysis\n",
    "                    if self.current_wpm == 200:  # Not analyzed yet\n",
    "                        clear_output()\n",
    "                        display(HTML(\"<div style='color: #f44336;'>‚ùå Please upload audio and complete analysis first, or select a default speech rate</div>\"))\n",
    "                        return\n",
    "                    wpm = self.current_wpm\n",
    "                else:\n",
    "                    wpm = self.speed_preset.value\n",
    "                \n",
    "                # üÜï Generate transcript (pass model selection)\n",
    "                transcript = self.transcript_generator.generate_transcript(\n",
    "                    slides=self.pdf_processor.slides_content,\n",
    "                    target_duration=self.duration_input.value,\n",
    "                    words_per_minute=wpm,\n",
    "                    style=self.style_dropdown.value,\n",
    "                    topic=self.topic_input.value,\n",
    "                    audience=self.audience_input.value,\n",
    "                    language=self.language_dropdown.value,\n",
    "                    model_name=self.model_dropdown.value,\n",
    "                    expert_role=self.expert_role.value if self.expert_role.value else None,\n",
    "                    include_tips=self.include_tips.value\n",
    "                )\n",
    "                \n",
    "                clear_output()\n",
    "                \n",
    "                # Display results\n",
    "                display(HTML(\"\"\"\n",
    "                <div class='success-box'>\n",
    "                    <h2 style=\"color: white; margin: 0;\">‚úÖ Transcript Generation Complete!</h2>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "                \n",
    "                # Format output\n",
    "                formatted_transcript = self._format_transcript(transcript)\n",
    "                display(HTML(f\"<div class='transcript-output'>{formatted_transcript}</div>\"))\n",
    "                \n",
    "                # Download buttons\n",
    "                self._create_download_buttons(transcript)\n",
    "                \n",
    "            except Exception as e:\n",
    "                clear_output()\n",
    "                display(HTML(f\"\"\"\n",
    "                <div style='color: #f44336; padding: 20px; border: 2px solid #f44336; border-radius: 8px;'>\n",
    "                    <h3>‚ùå Generation Failed</h3>\n",
    "                    <p>{str(e)}</p>\n",
    "                </div>\n",
    "                \"\"\"))\n",
    "    \n",
    "    def _format_transcript(self, transcript: str) -> str:\n",
    "        \"\"\"Format transcript output\"\"\"\n",
    "        lines = transcript.split('\\n')\n",
    "        formatted = \"\"\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Slide title\n",
    "            if line.startswith('Slide'):\n",
    "                formatted += f\"<h3 style='color: #2196F3; margin-top: 20px; border-left: 4px solid #2196F3; padding-left: 10px;'>üìÑ {line}</h3>\"\n",
    "            # Speech tips suggestions (marked with brackets)\n",
    "            elif '[' in line and ']' in line:\n",
    "                # Highlight suggestions\n",
    "                import re\n",
    "                highlighted = re.sub(r'\\[([^\\]]+)\\]', r'<span style=\"background: #FFF3E0; color: #F57C00; padding: 2px 6px; border-radius: 3px; font-weight: 500;\">[\\1]</span>', line)\n",
    "                formatted += f\"<p style='line-height: 1.8; margin: 10px 0;'>{highlighted}</p>\"\n",
    "            # General content\n",
    "            else:\n",
    "                formatted += f\"<p style='line-height: 1.8; margin: 10px 0;'>{line}</p>\"\n",
    "        \n",
    "        return formatted\n",
    "    \n",
    "    def _create_download_buttons(self, transcript: str):\n",
    "        \"\"\"Create download buttons\"\"\"\n",
    "        \n",
    "        # TXT Download\n",
    "        txt_content = transcript.encode('utf-8')\n",
    "        txt_b64 = base64.b64encode(txt_content).decode()\n",
    "        \n",
    "        filename = f\"transcript_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "        \n",
    "        display(HTML(f\"\"\"\n",
    "        <div style='margin-top: 20px; text-align: center;'>\n",
    "            <a href=\"data:text/plain;base64,{txt_b64}\" \n",
    "               download=\"{filename}.txt\"\n",
    "               style=\"display: inline-block; padding: 12px 30px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                      color: white; text-decoration: none; border-radius: 8px; font-weight: 500; margin: 10px;\">\n",
    "                üì• Download TXT Format\n",
    "            </a>\n",
    "        </div>\n",
    "        \"\"\"))\n",
    "\n",
    "print(\"‚úÖ Interactive UI is ready!\")\n",
    "print(\"üëá Please scroll down to start using\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7765d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display startup message\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ Application Starting...\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüìã Usage Steps:\")\n",
    "print(\"1Ô∏è‚É£  Upload your slides PDF\")\n",
    "print(\"2Ô∏è‚É£  Set speech duration\")\n",
    "print(\"3Ô∏è‚É£  Select speech rate (Slow/Medium/Fast/Auto Analysis)\")\n",
    "print(\"4Ô∏è‚É£  Select AI Model (GPT-5.1 Recommended ‚≠ê)\")\n",
    "print(\"5Ô∏è‚É£  Select speech style\")\n",
    "print(\"6Ô∏è‚É£  Fill in speech information\")\n",
    "print(\"7Ô∏è‚É£  Click 'Generate Transcript' button\")\n",
    "print(\"8Ô∏è‚É£  Download generated transcript\")\n",
    "print(\"\\n‚ú® Key Features:\")\n",
    "print(\"   ‚Ä¢ GPT-5.1 Model - Strongest multimodal understanding, deep analysis of slide content (text & images)\")\n",
    "print(\"   ‚Ä¢ GPT-4o Audio - Accurately calculates your speech rate\")\n",
    "print(\"   ‚Ä¢ 8 Languages Supported - Traditional Chinese/English/Simplified Chinese/Japanese/Korean/Spanish/French/German\")\n",
    "print(\"   ‚Ä¢ Speech Tips Suggestions - AI provides professional advice on gestures, tone, pauses, etc.\")\n",
    "print(\"   ‚Ä¢ Expert Role Play - AI writes as a specified expert, making content more professional and persuasive\")\n",
    "print(\"\\nüí° Expert Role Description:\")\n",
    "print(\"   After filling in the 'Expert Role' field, AI will write the transcript acting as that persona\")\n",
    "print(\"   e.g., 'Senior AI Researcher' explains from a technical expert's perspective\")\n",
    "print(\"        'PhD in Educational Psychology' explains from an educational expert's perspective\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Start the application\n",
    "app = TranscriptGeneratorUI()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
